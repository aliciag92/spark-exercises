{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spark API Roadmap / Cheatsheet](https://zgul.de/teaching/spark-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark library\n",
    "import pyspark\n",
    "\n",
    "#creating spark object (necessary to creating spark dfs)\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff3b4127400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fancy nice html representation\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading tips dataset from pydataset\n",
    "tips = pydataset.data('tips')\n",
    "\n",
    "#spark doesn't load any data until it has to\n",
    "df = spark.createDataFrame(tips)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load data w/ .show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pass a number in\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#common mistake\n",
    "df2 = df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassigning gives back nothing\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.show() is like a print statement, it doesn't return anything\n",
    "# Don't reassign to a variable\n",
    "#.show() is just to view contents\n",
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(total_bill=16.99, tip=1.01, sex='Female', smoker='No', day='Sun', time='Dinner', size=2),\n",
       " Row(total_bill=10.34, tip=1.66, sex='Male', smoker='No', day='Sun', time='Dinner', size=3),\n",
       " Row(total_bill=21.01, tip=3.5, sex='Male', smoker='No', day='Sun', time='Dinner', size=3),\n",
       " Row(total_bill=23.68, tip=3.31, sex='Male', smoker='No', day='Sun', time='Dinner', size=2),\n",
       " Row(total_bill=24.59, tip=3.61, sex='Female', smoker='No', day='Sun', time='Dinner', size=4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#work with values in the df\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(total_bill=16.99, tip=1.01, sex='Female', smoker='No', day='Sun', time='Dinner', size=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show row contents\n",
    "df.head(5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show value for tip\n",
    "df.head(5)[0].tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, size: bigint, day: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull specific columns w/ .select and pass col names you want\n",
    "df.select('total_bill', 'tip', 'size', 'day')\n",
    "#specified a transformation, and not an action (that is why we don't see anything b/c you need .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+---+\n",
      "|total_bill| tip|size|day|\n",
      "+----------+----+----+---+\n",
      "|     16.99|1.01|   2|Sun|\n",
      "|     10.34|1.66|   3|Sun|\n",
      "|     21.01| 3.5|   3|Sun|\n",
      "|     23.68|3.31|   2|Sun|\n",
      "|     24.59|3.61|   4|Sun|\n",
      "|     25.29|4.71|   4|Sun|\n",
      "|      8.77| 2.0|   2|Sun|\n",
      "|     26.88|3.12|   4|Sun|\n",
      "|     15.04|1.96|   2|Sun|\n",
      "|     14.78|3.23|   2|Sun|\n",
      "|     10.27|1.71|   2|Sun|\n",
      "|     35.26| 5.0|   4|Sun|\n",
      "|     15.42|1.57|   2|Sun|\n",
      "|     18.43| 3.0|   4|Sun|\n",
      "|     14.83|3.02|   2|Sun|\n",
      "|     21.58|3.92|   2|Sun|\n",
      "|     10.33|1.67|   3|Sun|\n",
      "|     16.29|3.71|   3|Sun|\n",
      "|     16.97| 3.5|   3|Sun|\n",
      "|     20.65|3.35|   3|Sat|\n",
      "+----------+----+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show values\n",
    "df.select('total_bill', 'tip', 'size', 'day').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#like sql, get back every col\n",
    "df.select('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'tip'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reference col name (spark col object), but no data\n",
    "df.tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(tip / total_bill)'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tip percentage\n",
    "df.tip / df.total_bill\n",
    "#syntax looks like pandas, but result is different\n",
    "#the column represents the transformation, but isn't full of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| (tip / total_bill)|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#specify w/ .select () and .show() to show results\n",
    "df.select(df.tip / df.total_bill).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(tip / total_bill)'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take expressions and store in a new col\n",
    "col = df.tip / df.total_bill\n",
    "col\n",
    "#holds expression that represents new col, but no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| (tip / total_bill)|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see what we end up with and make modifications\n",
    "df.select(col).show(5)\n",
    "#by default, name of col, is the operation that was performed\n",
    "#so add alias (transforms column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|            tip_pct|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using .alias to rename col\n",
    "df.select(col.alias('tip_pct')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add new col to df by doing .select('*', new_col.alias('new_col_name'))\n",
    "df.select(\"*\", col.alias('tip_pct')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the df is not modified b/c it was not reassigned\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to get df w/ tip percentage, we have to assign to variable\n",
    "df_with_tip_pct = df.select(\"*\", col.alias('tip_pct')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, mean, concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-In Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+\n",
      "|        avg(tip)|  sum(total_bill)|\n",
      "+----------------+-----------------+\n",
      "|2.99827868852459|4827.769999999999|\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use built in functions to apply them to cols\n",
    "df.select(mean(df.tip), sum(df.total_bill)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|concat(day, time)|\n",
      "+-----------------+\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#concatenate text from multiple strings together\n",
    "df.select(concat('day', 'time')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '` time`' given input columns: [day, sex, size, smoker, time, tip, total_bill];\n'Project [concat(day#4, ' time) AS concat(day,  time)#295]\n+- LogicalRDD [total_bill#0, tip#1, sex#2, smoker#3, day#4, time#5, size#6L], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9447030933a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#above doesn't look like good format, need to add space character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#used to concating w/ space character, but we get error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#b/c concat func is trying to resolve everything past it as a name of a col in the df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \"\"\"\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '` time`' given input columns: [day, sex, size, smoker, time, tip, total_bill];\n'Project [concat(day#4, ' time) AS concat(day,  time)#295]\n+- LogicalRDD [total_bill#0, tip#1, sex#2, smoker#3, day#4, time#5, size#6L], false\n"
     ]
    }
   ],
   "source": [
    "#above doesn't look like good format, need to add space character\n",
    "df.select(concat('day', ' ' 'time')).show(5)\n",
    "#used to concating w/ space character, but we get error \n",
    "#b/c concat func is trying to resolve everything past it as a name of a col in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for literal (lit) function, needs import\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|concat(day,  , time)|\n",
      "+--------------------+\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use .lit() and it'll show proper format w/ literal space character\n",
    "df.select(concat('day', lit(' '), 'time')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'CAST(tip AS STRING)'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar to type casting\n",
    "df.tip.cast('string')\n",
    "#gives back col object that represents the transformation specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tip: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply to df w/ .select()\n",
    "df.select(df.tip.cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| tip|\n",
      "+----+\n",
      "|1.01|\n",
      "|1.66|\n",
      "| 3.5|\n",
      "|3.31|\n",
      "|3.61|\n",
      "|4.71|\n",
      "| 2.0|\n",
      "|3.12|\n",
      "|1.96|\n",
      "|3.23|\n",
      "|1.71|\n",
      "| 5.0|\n",
      "|1.57|\n",
      "| 3.0|\n",
      "|3.02|\n",
      "|3.92|\n",
      "|1.67|\n",
      "|3.71|\n",
      "| 3.5|\n",
      "|3.35|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view results w/ .show()\n",
    "df.select(df.tip.cast('string')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|time|\n",
      "+----+\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now, try doing this to string value and cast to integer, gives back nulls\n",
    "df.select(df.time.cast('int')).show()\n",
    "#nulls are like numpy.nan or python None, to indicate absence of a value\n",
    "#theres no error, like we're used to, spark just converts to 'null'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string manipulation w/ regex\n",
    "#apply to every value in a col\n",
    "from pyspark.sql.functions import regexp_extract, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|regexp_extract(time, (\\w).*, 1)|\n",
      "+-------------------------------+\n",
      "|                              D|\n",
      "|                              D|\n",
      "|                              D|\n",
      "|                              D|\n",
      "|                              D|\n",
      "+-------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract pieces of a col (the first thing from time col)\n",
    "df.select(\n",
    "    regexp_extract('time', r'(\\w).*', 1)\n",
    ").show(5)                   #first alphanumeric char, 1 to get contents of first capture group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|first_letter|\n",
      "+------------+\n",
      "|           D|\n",
      "|           D|\n",
      "|           D|\n",
      "|           D|\n",
      "|           D|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add alias\n",
    "df.select(\n",
    "    regexp_extract('time', r'(\\w).*', 1).alias('first_letter')\n",
    ").show(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|  time|first_letter|\n",
      "+------+------------+\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add in original time col\n",
    "df.select(\n",
    "    'time',\n",
    "    regexp_extract('time', r'(\\w).*', 1).alias('first_letter')\n",
    ").show(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-----------------------------------+\n",
      "|  time|first_letter|regexp_replace(time, [aeiou], X, 1)|\n",
      "+------+------------+-----------------------------------+\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "+------+------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use regexp_replace (like re.sub or .str.replace in pandas)\n",
    "df.select(\n",
    "    'time',\n",
    "    regexp_extract('time', r'(\\w).*', 1).alias('first_letter'),\n",
    "    regexp_replace('time', r'[aeiou]', 'X')\n",
    ").show(5)                #replace any of the vowels w/ a capital X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when and otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like case... when in sql\n",
    "#or like np.where (when it meets this condition, then do one thing)\n",
    "#or like if function in excel\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint, tip_pct: double]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modify df so that it now contains tip_pct col\n",
    "df = df.select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct')\n",
    ")\n",
    "#adds tip percentage column\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+-------------------------------------------------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|CASE WHEN (tip_pct > 0.2) THEN Good Tip ELSE Not Good Tip END|\n",
      "+----------+----+------+------+---+------+----+-------------------+-------------------------------------------------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|                                                 Not Good Tip|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|                                                 Not Good Tip|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|                                                 Not Good Tip|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|                                                 Not Good Tip|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|                                                 Not Good Tip|\n",
      "+----------+----+------+------+---+------+----+-------------------+-------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now select everything \n",
    "#and when the tip_pct is greater than .2, then say 'Good tip'\n",
    "#otherwise, say 'not good tip'\n",
    "df.select(\n",
    "    '*', \n",
    "    when(df.tip_pct > .2, 'Good Tip').otherwise('Not Good Tip')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+\n",
      "|            tip_pct|tip_description|\n",
      "+-------------------+---------------+\n",
      "|0.05944673337257211|   Not Good Tip|\n",
      "|0.16054158607350097|   Not Good Tip|\n",
      "|0.16658733936220846|   Not Good Tip|\n",
      "| 0.1397804054054054|   Not Good Tip|\n",
      "|0.14680764538430255|   Not Good Tip|\n",
      "|0.18623962040332148|   Not Good Tip|\n",
      "|0.22805017103762829|       Good Tip|\n",
      "|0.11607142857142858|   Not Good Tip|\n",
      "|0.13031914893617022|   Not Good Tip|\n",
      "| 0.2185385656292287|       Good Tip|\n",
      "+-------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to clean up above output, add alias to when/otherwise statement\n",
    "#and don't select everything, just tip_pct col instead of everything\n",
    "df.select(\n",
    "    'tip_pct', \n",
    "    (when(df.tip_pct > .2, 'Good Tip').otherwise('Not Good Tip')).alias('tip_description')\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark API Mini Exercises\n",
    "Copy the code below to create a pandas dataframe with 20 rows and 3 columns:\n",
    "\n",
    "`import pandas as pd\n",
    "import numpy as np`\n",
    "\n",
    "`np.random.seed(13)`\n",
    "\n",
    "`pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spark Dataframe Basics\n",
    "\n",
    "#### i. Use the starter code above to create a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Convert the pandas dataframe to a spark dataframe. From this point forward, do all of your work with the spark dataframe, not the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Show the first 3 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Show the first 7 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. View a summary of the data using `.describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Use `.select` to create a new dataframe with just the `n` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. Use `.select` to create a new dataframe with just the `group` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viii. Use `.select` to create a new dataframe with the `group` column and the `abool` column renamed to `a_boolean_value`. Show the first 3 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ix. Use `.select` to create a new dataframe with the `group` column and the `n` column renamed to `a_numeric_value`. Show the first 6 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Column Manipulation\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe. Store the spark dataframe in a variable named `df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Use `.select` to add 4 to the `n` column. Show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Subtract 5 from the `n` column and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Multiply the `n` column by 2. View the results along with the original numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Add a new column named `n2` that is the `n` value multiplied by -1. Show the first 4 rows of your dataframe. You should see the original `n` value as well as `n2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Add a new column named `n3` that is the n value squared. Show the first 5 rows of your dataframe. You should see both `n`, `n2`, and `n3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. What happens when you run the code below?\n",
    "\n",
    "`df.group + df.abool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viii. What happens when you run the code below? What is the difference between this and the previous code sample?\n",
    "\n",
    "`df.select(df.group + df.abool)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ix. Try adding various other columns together. What are the results of combining the different data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
